{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A) summarize the main results in the paper;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B) Reproduce the results in Figure 1 in paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C) Perform the same empirical comparison on the bandit problem provided in the Sutton & Barto book (which we discussed in class). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import numpy\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_bandits(results):\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.style.use('seaborn-whitegrid')\n",
    "    time_steps = len(np.array(results).T[0])\n",
    "    plt.plot(np.arange(0, time_steps), [ts[0] for ts in results[:time_steps]], color=\"blue\" )\n",
    "    plt.plot(np.arange(0, time_steps), [ts[1] for ts in results[:time_steps]], color=\"green\" )\n",
    "    plt.plot(np.arange(0, time_steps), [ts[2] for ts in results[:time_steps]], color=\"red\" )\n",
    "    plt.plot(np.arange(0, time_steps), [ts[3] for ts in results[:time_steps]], color=\"teal\" )\n",
    "    plt.plot(np.arange(0, time_steps), [ts[4] for ts in results[:time_steps]], color=\"magenta\")\n",
    "    plt.plot(np.arange(0, time_steps), [ts[5] for ts in results[:time_steps]], color=\"yellow\" )\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormalBandit:\n",
    "    def __init__(self, mu, sigma):\n",
    "        self.mu = mu\n",
    "        self.sigma = sigma\n",
    "\n",
    "    def reward(self):\n",
    "        return np.random.normal(self.mu, self.sigma, 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BanditTrials:\n",
    "    \n",
    "    def __init__(self, bandits, n_trials=10, n_time_steps=100):\n",
    "        self.n_trials = n_trials\n",
    "        self.n_time_steps = n_time_steps\n",
    "        self.total_trial_results = []\n",
    "        self.bandits = bandits\n",
    "        \n",
    "    def run_action_elimination_trials(self):\n",
    "        self.run_trials(ActionEliminationBanditTrial)\n",
    "\n",
    "    def run_ucb_trials(self):\n",
    "        self.run_trials(UCBBanditTrial)\n",
    "\n",
    "        \n",
    "    def run_trials(self, strategy):\n",
    "        self.total_trial_results = []\n",
    "        h1 = self.H1([b.mu for b in self.bandits])\n",
    "        for trial_num in np.arange(0, self.n_trials):\n",
    "            trial = strategy(self.bandits)\n",
    "            trial.run_trial(time_steps=self.n_time_steps)\n",
    "            self.total_trial_results.append(trial.pull_count_per_timestep / h1)\n",
    "            print(\"Trial {} of {} complete\".format(trial_num + 1, self.n_trials), end='\\r')\n",
    "\n",
    "            \n",
    "    \n",
    "    def H1(self, true_means):\n",
    "        \"\"\" Hardness of the Trial\"\"\"\n",
    "        optimal_mean = np.max(true_means)        \n",
    "        delta = optimal_mean - true_means\n",
    "        return np.sum(np.power(delta[1:], -2))\n",
    "\n",
    "    def results_as_probability(self):\n",
    "        return [softmax(result) for result in np.mean(self.total_trial_results, axis=0)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class ActionEliminationBanditTrial:\n",
    "    def __init__(self, bandits):\n",
    "        \"\"\"\n",
    "        bandit_means\n",
    "            a list of means that will be used to build the bandits\n",
    "        r_k = 1\n",
    "            is the number of samples per epoch for each arm. \n",
    "        \"\"\"\n",
    "        self.bandits = bandits \n",
    "        \n",
    "        self.bandit_count = len(self.bandits)\n",
    "        self.k = self.bandit_count\n",
    "        \n",
    "        bandit_means = [b.mu for b in bandits ]\n",
    "        self.optimal_bandit = np.argmax(bandit_means)\n",
    "        self.rewards_per_arm = [[] for _x in np.arange(0, self.bandit_count)]\n",
    "        self.estimated_action_reward = np.zeros(self.bandit_count)\n",
    "\n",
    "        self.delta = 0.1       \n",
    "        self.active_bandits = np.ones(self.bandit_count)\n",
    "\n",
    "        self.pull_count_per_timestep = []\n",
    "\n",
    "    def empirical_mean(self, bandit_index):\n",
    "        r\"\"\"\n",
    "        Calculate the empirical mean of a given bandit (indexed). When an arm is hasn't been pulled, return -Infinity\n",
    "        \"\"\"\n",
    "        if len(self.rewards_per_arm[bandit_index]) == 0:\n",
    "            return -np.Inf\n",
    "        return np.mean(self.rewards_per_arm[bandit_index])\n",
    "    \n",
    "    def active_bandit_indexes(self):\n",
    "        r\"\"\"\n",
    "        self.active_bandits is |n|. Return only the indexes == 1.\n",
    "        \"\"\"\n",
    "        return np.nonzero(self.active_bandits)[0]\n",
    "    \n",
    "    def estimated_best_bandit_mean(self):\n",
    "        \"\"\" returns a tuple with the best bandit index and the empirical mean\"\"\"\n",
    "        all_empirical_means = [self.empirical_mean(idx) for idx,rewards in enumerate(self.bandits)]\n",
    "        best_arm_index = np.nanargmax(all_empirical_means)\n",
    "        return (best_arm_index, all_empirical_means[best_arm_index])\n",
    "\n",
    "    def arm(self, idx):\n",
    "        return self.bandits[idx]\n",
    "\n",
    "    def pull_arm(self, idx):\n",
    "        return self.arm(idx).reward()\n",
    "    \n",
    "    def drop_arm(self, idx):\n",
    "        self.active_bandits[idx] = 0\n",
    "        \n",
    "    def C_ik(self, bandit_index):\n",
    "        k = len(self.rewards_per_arm[bandit_index])\n",
    "        n = self.bandit_count        \n",
    "        if k == 0:\n",
    "            return 0\n",
    "\n",
    "        A = np.power(np.pi , 2 ) / 3\n",
    "        B = n * np.power(k, 2) / self.delta   \n",
    "        \n",
    "        return np.sqrt( np.log( A * B) / k  )\n",
    "    \n",
    "    def stopping_condition_reached(self):\n",
    "        return len(self.active_bandit_indexes()) == 1\n",
    "            \n",
    "    def run_trial(self, time_steps=500):\n",
    "        current_epoch = 0\n",
    "        for step in np.arange(0,time_steps):\n",
    "            # Stopping Condition\n",
    "            if self.stopping_condition_reached():\n",
    "                mean = self.estimated_best_bandit_mean()\n",
    "                print(\"Stopping. Best Arm: {}. Found in {} time steps\".format(mean[0], step))\n",
    "                print(\"Estimated mean: {}. \".format(mean[1]))\n",
    "                print(\"Empirical mean: {}. \".format(self.arm(self.optimal_bandit).mu))\n",
    "                break\n",
    "            \n",
    "            bandit_index = np.random.choice(self.active_bandit_indexes())\n",
    "            self.rewards_per_arm[bandit_index].append(self.pull_arm(bandit_index))\n",
    "            \n",
    "            reference_arm = self.estimated_best_bandit_mean()\n",
    "            reference_C_t = self.C_ik(reference_arm[0])\n",
    "\n",
    "            for bandit_idx in self.active_bandit_indexes():\n",
    "                candidate_arm_mean = self.empirical_mean(bandit_idx)\n",
    "                candidate_C_t = self.C_ik(bandit_idx)\n",
    "                lhs = reference_arm[1] - reference_C_t\n",
    "                rhs = candidate_arm_mean + candidate_C_t\n",
    "                if lhs >= rhs and rhs > (-np.inf):\n",
    "#                    print(\"Dropping:  {}: {} < {}\".format(bandit_idx, lhs, rhs ))\n",
    "                    self.drop_arm(bandit_idx)\n",
    "\n",
    "            # calculate P(I_t = i)\n",
    "            if current_epoch > 0:\n",
    "                self.pull_count_per_timestep.append([len(self.rewards_per_arm[idx]) for idx, _b in enumerate(self.bandits)])\n",
    "            if step > 0 and step % (self.k - 1) == 0:\n",
    "                current_epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UCBBanditTrial:\n",
    "    def __init__(self, bandits):\n",
    "        \"\"\"\n",
    "        bandit_means\n",
    "            a list of means that will be used to build the bandits\n",
    "        \"\"\"\n",
    "        self.bandits = bandits \n",
    "        \n",
    "        self.bandit_count = len(self.bandits)\n",
    "        \n",
    "        bandit_means = [b.mu for b in bandits ]\n",
    "        self.optimal_bandit = np.argmax(bandit_means)\n",
    "        self.rewards_per_arm = [[] for _x in np.arange(0, self.bandit_count)]\n",
    "        self.estimated_action_reward = np.zeros(self.bandit_count)\n",
    "\n",
    "        self.delta = 0.1       \n",
    "        self.pull_count_per_timestep = []\n",
    "\n",
    "    def arm(self, idx):\n",
    "        return self.bandits[idx]\n",
    "\n",
    "    def pull_arm(self, idx):\n",
    "        return self.arm(idx).reward()\n",
    "    \n",
    "    def empirical_mean(self, bandit_index):\n",
    "        r\"\"\"\n",
    "        Calculate the empirical mean of a given bandit (indexed). When an arm is hasn't been pulled, return -Infinity\n",
    "        \"\"\"\n",
    "        if len(self.rewards_per_arm[bandit_index]) == 0:\n",
    "            return -np.Inf\n",
    "        return np.mean(self.rewards_per_arm[bandit_index])\n",
    "    \n",
    "    def all_empirical_means(self):\n",
    "        return [self.empirical_mean(idx) for idx,rewards in enumerate(self.bandits)]\n",
    "    \n",
    "    def estimated_best_bandit_mean(self):\n",
    "        \"\"\" returns a tuple with the best bandit index and the empirical mean\"\"\"\n",
    "        means = self.all_empirical_means()\n",
    "        best_arm_index = np.nanargmax(means)\n",
    "        return (best_arm_index, means[best_arm_index])\n",
    "\n",
    "        \n",
    "    def C_ik(self, bandit_index):\n",
    "        k = len(self.rewards_per_arm[bandit_index])\n",
    "        n = self.bandit_count        \n",
    "        if k == 0:\n",
    "            return 0\n",
    "\n",
    "        A = np.power(np.pi , 2 ) / 3\n",
    "        B = n * np.power(k, 2) / self.delta   \n",
    "        return np.sqrt( np.log( A * B) / k  )\n",
    "    \n",
    "    def stopping_condition_reached(self):\n",
    "        return False\n",
    "    \n",
    "    def print_stopping_condition(self, step):\n",
    "        mean = self.estimated_best_bandit_mean()\n",
    "        print(\"Stopping. Best Arm: {}. Found in {} time steps\".format(mean[0], step))\n",
    "        print(\"Estimated mean: {}. \".format(mean[1]))\n",
    "        print(\"Empirical mean: {}. \".format(self.arm(self.optimal_bandit).mu))\n",
    "        \n",
    "    def run_trial(self, time_steps=500):\n",
    "        for step in np.arange(0,time_steps):\n",
    "            # Stopping Condition\n",
    "            if self.stopping_condition_reached():\n",
    "                self.print_stopping_condition(step)\n",
    "                break\n",
    "\n",
    "            # check to see if we haven't sampled a bandit yet:\n",
    "            unexplored = np.where(np.isinf(self.all_empirical_means()))[0]\n",
    "            if len(unexplored) != 0:\n",
    "                # grab the next one:\n",
    "                bandit_index = unexplored[0]\n",
    "            else:\n",
    "                results = [mean + self.C_ik(idx) for idx,mean in enumerate(self.all_empirical_means())]\n",
    "                bandit_index = np.argmax(results)\n",
    "\n",
    "            self.rewards_per_arm[bandit_index].append(self.pull_arm(bandit_index))\n",
    "            \n",
    "            reference_arm = self.estimated_best_bandit_mean()\n",
    "            reference_C_t = self.C_ik(reference_arm[0])\n",
    "\n",
    "            for bandit_idx,_b in enumerate(self.bandits):\n",
    "                candidate_arm_mean = self.empirical_mean(bandit_idx)\n",
    "                candidate_C_t = self.C_ik(bandit_idx)\n",
    "                lhs = reference_arm[1] - reference_C_t\n",
    "                # TODO second best arm:\n",
    "                rhs = candidate_arm_mean + candidate_C_t\n",
    "\n",
    "            self.pull_count_per_timestep.append([len(self.rewards_per_arm[idx]) for idx, _b in enumerate(self.bandits)])\n",
    "\n",
    "            \n",
    "BANDIT_MEANS = [ 1, 4/5, 3/5, 2/5, 1/5, 0]\n",
    "SIGMA = 1/4\n",
    "\n",
    "#trial = UCBBanditTrial([NormalBandit(mean, SIGMA) for mean in BANDIT_MEANS])\n",
    "#trial.run_trial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "BANDIT_MEANS = [ 1, 4/5, 3/5, 2/5, 1/5, 0]\n",
    "SIGMA = 1/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 of 5 complete\r"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bandits = [NormalBandit(mean, SIGMA) for mean in BANDIT_MEANS]\n",
    "trials = BanditTrials(bandits, n_trials=5, n_time_steps=1000)\n",
    "trials.run_ucb_trials()\n",
    "results = trials.results_as_probability()\n",
    "plot_bandits(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D) discuss in a short paragraph a concrete application in which you think regret optimization would be more useful than best arm identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
