{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A) summarize the main results in the paper;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B) Reproduce the results in Figure 1 in paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C) Perform the same empirical comparison on the bandit problem provided in the Sutton & Barto book (which we discussed in class). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import numpy\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormalBandit:\n",
    "    def __init__(self, mu, sigma):\n",
    "        self.mu = mu\n",
    "        self.sigma = sigma\n",
    "\n",
    "    def reward(self):\n",
    "        return np.random.normal(self.mu, self.sigma, 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BanditTrials:\n",
    "    \n",
    "    def __init__(self, bandits, n_trials=10, n_time_steps=100):\n",
    "        self.n_trials = n_trials\n",
    "        self.n_time_steps = n_time_steps\n",
    "        self.total_trial_results = []\n",
    "        self.bandits = bandits\n",
    "        \n",
    "    def run_action_elimination_trials(self):\n",
    "        self.run_trials(ActionEliminationBanditTrial)\n",
    "\n",
    "    def run_ucb_trials(self):\n",
    "        self.run_trials(UCBBanditTrial)\n",
    "\n",
    "        \n",
    "    def run_trials(self, strategy):\n",
    "        self.total_trial_results = []\n",
    "        h1 = self.H1([b.mu for b in self.bandits])\n",
    "        for trial_num in np.arange(0, self.n_trials):\n",
    "            trial = strategy(self.bandits)\n",
    "            trial.run_trial(time_steps=self.n_time_steps)\n",
    "            self.total_trial_results.append(trial.pull_count_per_timestep / h1)\n",
    "            print(\"Trial {} of {} complete\".format(trial_num + 1, self.n_trials), end='\\r')\n",
    "\n",
    "            \n",
    "    \n",
    "    def H1(self, true_means):\n",
    "        \"\"\" Hardness of the Trial\"\"\"\n",
    "        optimal_mean = np.max(true_means)        \n",
    "        delta = optimal_mean - true_means\n",
    "        return np.sum(np.power(delta[1:], -2))\n",
    "\n",
    "    def results_as_probability(self):\n",
    "        return [softmax(result) for result in np.mean(self.total_trial_results, axis=0)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class ActionEliminationBanditTrial:\n",
    "    def __init__(self, bandits):\n",
    "        \"\"\"\n",
    "        bandit_means\n",
    "            a list of means that will be used to build the bandits\n",
    "        r_k = 1\n",
    "            is the number of samples per epoch for each arm. \n",
    "        \"\"\"\n",
    "        self.bandits = bandits \n",
    "        \n",
    "        self.bandit_count = len(self.bandits)\n",
    "        self.k = self.bandit_count\n",
    "        \n",
    "        bandit_means = [b.mu for b in bandits ]\n",
    "        self.optimal_bandit = np.argmax(bandit_means)\n",
    "        self.rewards_per_arm = [[] for _x in np.arange(0, self.bandit_count)]\n",
    "        self.delta = 0.1       \n",
    "        self.active_bandits = np.ones(self.bandit_count)\n",
    "        self.pull_count_per_timestep = []\n",
    "\n",
    "    def empirical_mean(self, bandit_index):\n",
    "        r\"\"\"\n",
    "        Calculate the empirical mean of a given bandit (indexed). When an arm is hasn't been pulled, return -Infinity\n",
    "        \"\"\"\n",
    "        if len(self.rewards_per_arm[bandit_index]) == 0:\n",
    "            return -np.Inf\n",
    "        return np.mean(self.rewards_per_arm[bandit_index])\n",
    "    \n",
    "    def active_bandit_indexes(self):\n",
    "        r\"\"\"\n",
    "        self.active_bandits is |n|. Return only the indexes == 1.\n",
    "        \"\"\"\n",
    "        return np.nonzero(self.active_bandits)[0]\n",
    "    \n",
    "    def estimated_best_bandit_mean(self):\n",
    "        \"\"\" returns a tuple with the best bandit index and the empirical mean\"\"\"\n",
    "        all_empirical_means = [self.empirical_mean(idx) for idx,rewards in enumerate(self.bandits)]\n",
    "        best_arm_index = np.nanargmax(all_empirical_means)\n",
    "        return (best_arm_index, all_empirical_means[best_arm_index])\n",
    "\n",
    "    def arm(self, idx):\n",
    "        return self.bandits[idx]\n",
    "\n",
    "    def pull_arm(self, idx):\n",
    "        return self.arm(idx).reward()\n",
    "    \n",
    "    def drop_arm(self, idx):\n",
    "        self.active_bandits[idx] = 0\n",
    "        \n",
    "    def C_ik(self, bandit_index):\n",
    "        k = len(self.rewards_per_arm[bandit_index])\n",
    "        n = self.bandit_count        \n",
    "        if k == 0:\n",
    "            return 0\n",
    "\n",
    "        A = np.power(np.pi , 2 ) / 3\n",
    "        B = n * np.power(k, 2) / self.delta   \n",
    "        \n",
    "        return np.sqrt( np.log( A * B) / k  )\n",
    "    \n",
    "    def stopping_condition_reached(self):\n",
    "        return False\n",
    "        return len(self.active_bandit_indexes()) == 1\n",
    "            \n",
    "    def run_trial(self, time_steps=500):\n",
    "        current_epoch = 0\n",
    "        active_bandits_for_epoch = self.active_bandit_indexes()\n",
    "        for step in np.arange(0,time_steps):\n",
    "            # Stopping Condition\n",
    "            if self.stopping_condition_reached():\n",
    "                mean = self.estimated_best_bandit_mean()\n",
    "                print(\"Stopping. Best Arm: {}. Found in {} time steps\".format(mean[0], step))\n",
    "                print(\"Estimated mean: {}. \".format(mean[1]))\n",
    "                print(\"Empirical mean: {}. \".format(self.arm(self.optimal_bandit).mu))\n",
    "                break\n",
    "            \n",
    "            \n",
    "            for bandit_index in active_bandits_for_epoch:\n",
    "                \n",
    "                self.rewards_per_arm[bandit_index].append(self.pull_arm(bandit_index))\n",
    "\n",
    "                reference_arm = self.estimated_best_bandit_mean()\n",
    "                reference_C_t = self.C_ik(reference_arm[0])\n",
    "\n",
    "                for bandit_idx in self.active_bandit_indexes():\n",
    "                    candidate_arm_mean = self.empirical_mean(bandit_idx)\n",
    "                    candidate_C_t = self.C_ik(bandit_idx)\n",
    "                    lhs = reference_arm[1] - reference_C_t\n",
    "                    rhs = candidate_arm_mean + candidate_C_t\n",
    "                    if lhs >= rhs and rhs > (-np.inf):\n",
    "    #                    print(\"Dropping:  {}: {} < {}\".format(bandit_idx, lhs, rhs ))\n",
    "                        self.drop_arm(bandit_idx)\n",
    "\n",
    "            # calculate P(I_t = i)\n",
    "            if current_epoch > 0:\n",
    "                self.pull_count_per_timestep.append([len(self.rewards_per_arm[idx]) for idx, _b in enumerate(self.bandits)])\n",
    "\n",
    "            # increment epoch and reset the list of available bandits\n",
    "            if step > 0 and step % (self.k - 1) == 0:\n",
    "                active_bandits_for_epoch = self.active_bandit_indexes()\n",
    "                current_epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UCBBanditTrial:\n",
    "    def __init__(self, bandits):\n",
    "        \"\"\"\n",
    "        bandit_means\n",
    "            a list of means that will be used to build the bandits\n",
    "        \"\"\"\n",
    "        self.bandits = bandits \n",
    "        self.bandit_count = len(self.bandits)\n",
    "        \n",
    "        bandit_means = [b.mu for b in bandits ]\n",
    "        self.optimal_bandit = np.argmax(bandit_means)\n",
    "        self.rewards_per_arm = [[] for _x in np.arange(0, self.bandit_count)]\n",
    "        self.delta = 0.1       \n",
    "        self.pull_count_per_timestep = []\n",
    "\n",
    "    def arm(self, idx):\n",
    "        return self.bandits[idx]\n",
    "\n",
    "    def pull_arm(self, idx):\n",
    "        return self.arm(idx).reward()\n",
    "    \n",
    "    def empirical_mean(self, bandit_index):\n",
    "        r\"\"\"\n",
    "        Calculate the empirical mean of a given bandit (indexed). When an arm is hasn't been pulled, return -Infinity\n",
    "        \"\"\"\n",
    "        if len(self.rewards_per_arm[bandit_index]) == 0:\n",
    "            return -np.Inf\n",
    "        return np.mean(self.rewards_per_arm[bandit_index])\n",
    "    \n",
    "    def all_empirical_means(self):\n",
    "        return [self.empirical_mean(idx) for idx,rewards in enumerate(self.bandits)]\n",
    "    \n",
    "    def estimated_best_bandit_mean(self):\n",
    "        \"\"\" returns a tuple with the best bandit index and the empirical mean\"\"\"\n",
    "        means = self.all_empirical_means()\n",
    "        best_arm_index = np.nanargmax(means)\n",
    "        return (best_arm_index, means[best_arm_index])\n",
    "\n",
    "        \n",
    "    def C_ik(self, bandit_index):\n",
    "        k = len(self.rewards_per_arm[bandit_index])\n",
    "        n = self.bandit_count        \n",
    "        if k == 0:\n",
    "            return 0\n",
    "\n",
    "        A = np.power(np.pi , 2 ) / 3\n",
    "        B = n * np.power(k, 2) / self.delta   \n",
    "        return np.sqrt( np.log( A * B) / k  )\n",
    "    \n",
    "    def stopping_condition_reached(self):\n",
    "        # TODO: implement this:\n",
    "        return False\n",
    "    \n",
    "    def print_stopping_condition(self, step):\n",
    "        mean = self.estimated_best_bandit_mean()\n",
    "        print(\"Stopping. Best Arm: {}. Found in {} time steps\".format(mean[0], step))\n",
    "        print(\"Estimated mean: {}. \".format(mean[1]))\n",
    "        print(\"Empirical mean: {}. \".format(self.arm(self.optimal_bandit).mu))\n",
    "        \n",
    "    def best_filtered_bandit_index(self, bandit_indexes):\n",
    "        results = [mean for idx, mean in enumerate(self.all_empirical_means()) if idx in bandit_indexes]\n",
    "        return (np.argmax(results), results)\n",
    "        \n",
    "    def run_trial(self, time_steps=500):\n",
    "        for step in np.arange(0,time_steps):\n",
    "            # Stopping Condition\n",
    "            if self.stopping_condition_reached():\n",
    "                self.print_stopping_condition(step)\n",
    "                break\n",
    "\n",
    "            # check to see if we haven't sampled a bandit yet:\n",
    "            unexplored = np.where(np.isinf(self.all_empirical_means()))[0]\n",
    "\n",
    "            if len(unexplored) != 0:\n",
    "                # grab the next one:\n",
    "                best_bandit_index = unexplored[0]\n",
    "            else:\n",
    "                best_bandit_index, results = self.best_filtered_bandit_index(np.arange(0, self.bandit_count))\n",
    "                best_mean = results[best_bandit_index]\n",
    "                \n",
    "                filtered_indexes = np.nonzero(np.select([results != best_mean], [results]))[0]\n",
    "                second_best_bandit_index, _ = self.best_filtered_bandit_index(filtered_indexes)\n",
    "                second_best_mean = results[second_best_bandit_index]\n",
    "                \n",
    "                \n",
    "                lhs = best_mean - self.C_ik(best_bandit_index)\n",
    "                rhs = second_best_mean + self.C_ik(second_best_bandit_index)\n",
    "                \n",
    "                if lhs > rhs:\n",
    "                    self.print_stopping_condition(step)\n",
    "                    break                \n",
    "\n",
    "            self.rewards_per_arm[best_bandit_index].append(self.pull_arm(best_bandit_index))\n",
    "            self.pull_count_per_timestep.append([len(self.rewards_per_arm[idx]) for idx, _b in enumerate(self.bandits)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "bandits = [NormalBandit(mean, SIGMA) for mean in BANDIT_MEANS]\n",
    "trials = UCBBanditTrial(bandits)\n",
    "trials.run_trial(time_steps=4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.arange(10)\n",
    "np.nonzero(np.select([x != 4], [x]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "BANDIT_MEANS = [ 1, 4/5, 3/5, 2/5, 1/5, 0]\n",
    "SIGMA = 1/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 100 of 100 complete\r"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def softmax(x):\n",
    "#    e_x = np.exp(x - np.max(x))\n",
    "    e_x = np.exp(x)\n",
    "    return e_x / np.sum(e_x)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_bandits(results):\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.style.use('seaborn-whitegrid')\n",
    "    time_steps = len(np.array(results).T[0])\n",
    "\n",
    "    plt.plot(np.arange(0, time_steps), [ts[0] for ts in results[:time_steps]], color=\"blue\" )\n",
    "    plt.plot(np.arange(0, time_steps), [ts[1] for ts in results[:time_steps]], color=\"green\" )\n",
    "    plt.plot(np.arange(0, time_steps), [ts[2] for ts in results[:time_steps]], color=\"red\" )\n",
    "    plt.plot(np.arange(0, time_steps), [ts[3] for ts in results[:time_steps]], color=\"teal\" )\n",
    "    plt.plot(np.arange(0, time_steps), [ts[4] for ts in results[:time_steps]], color=\"magenta\")\n",
    "    plt.plot(np.arange(0, time_steps), [ts[5] for ts in results[:time_steps]], color=\"yellow\" )\n",
    "    plt.show()\n",
    "\n",
    "bandits = [NormalBandit(mean, SIGMA) for mean in BANDIT_MEANS]\n",
    "trials = BanditTrials(bandits, n_trials=100, n_time_steps=4000)\n",
    "trials.run_action_elimination_trials()\n",
    "\n",
    "\n",
    "results = trials.results_as_probability()\n",
    "plot_bandits(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bandits = [NormalBandit(mean, SIGMA) for mean in BANDIT_MEANS]\n",
    "trials = BanditTrials(bandits, n_trials=100, n_time_steps=200)\n",
    "trials.run_ucb_trials()\n",
    "results = trials.results_as_probability()\n",
    "plot_bandits(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D) discuss in a short paragraph a concrete application in which you think regret optimization would be more useful than best arm identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
